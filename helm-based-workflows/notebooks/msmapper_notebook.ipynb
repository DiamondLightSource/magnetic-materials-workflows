{
 "cells": [
  {
   "cell_type": "code",
   "id": "41b9322b-f87f-4aad-ad18-8274890181ec",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "source": [
    "datadir = \"\"\n",
    "scan_numbers = \"\"\n",
    "step = [0.002]\n",
    "reduce_box = True\n",
    "normalisation='rc'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dec41e54-cc52-4a63-9bbb-29eba933c5ec",
   "metadata": {},
   "source": [
    "# Run MSMapper and Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "db850d5c-175d-4687-bfc3-13ba82e47d46",
   "metadata": {},
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the location of msmapper\n",
    "CONFIG = '/tmp/msmapper_config'\n",
    "MSMAPPER = '/opt/msmapper/msmapper'\n",
    "TMP_BEAN = '/tmp/tmp_remap.json'\n",
    "TMP_NXS = '/tmp/tmp_remap.nxs'\n",
    "OUTPUT = '/tmp/msmapper_result.png'\n",
    "LOG = '/tmp/msmapper_result.log'\n",
    "SHELL_CMD = ' '.join([MSMAPPER, \"-configuration\", CONFIG, \"-bean %s\"])\n",
    "\n",
    "if not os.path.exists(MSMAPPER):\n",
    "    raise ValueError(\"MSMAPPER not found\")\n",
    "\n",
    "# make config dir\n",
    "os.makedirs(CONFIG, exist_ok=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inputs\n",
    "processing_directory = os.path.join(datadir, \"processing\")\n",
    "if not os.path.isdir(datadir):\n",
    "    raise ValueError(\"data directory not found\")\n",
    "if not os.path.isdir(processing_directory):\n",
    "    raise ValueError(\"processing directory not found\")\n",
    "\n",
    "scan_numbers = np.fromstring(str(scan_numbers).strip('[]'), dtype=int, sep=',')\n",
    "inpath = [os.path.join(datadir, f\"{n}.nxs\") for n in scan_numbers]\n",
    "for file in inpath:\n",
    "    if not os.path.exists(file):\n",
    "        raise ValueError(f\"file not found: {file}\")\n",
    "\n",
    "if len(scan_numbers) == 1:\n",
    "    outpath = os.path.join(processing_directory, f\"{scan_numbers[0]}_workflows_msmapper.nxs\")\n",
    "else:\n",
    "    outpath = os.path.join(processing_directory, f\"{scan_numbers[0]}-{scan_numbers[-1]}_workflows_msmapper.nxs\")\n",
    "print(\"inpath: \", inpath)\n",
    "print(\"outpath: \", outpath)\n",
    "\n",
    "step = np.fromstring(str(step).strip('[]'), sep=',').tolist()\n",
    "print(f\"step = {step}\")"
   ],
   "id": "651e7214d5db6a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# msmapper runner\n",
    "def msmapper(bean_file):\n",
    "    \"\"\"\n",
    "    Run msmapper in subprocess\n",
    "      (python 3.9)$ msmapper -bean bean_file\n",
    "    :param bean_file: str location of json file with input options\n",
    "    :return: Returns on completion\n",
    "    \"\"\"\n",
    "    print('\\n\\n\\n################# Starting msmapper ###################')\n",
    "    cmd = SHELL_CMD % bean_file\n",
    "    print(f\"Running command:\\n{cmd}\\n\\n\\n\")\n",
    "    output = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    print('Output written to:', LOG)\n",
    "    with open(LOG, 'w') as f:\n",
    "        f.write(f\"Running command:\\n{cmd}\\n\\n\\n\")\n",
    "        f.write(output.stderr)\n",
    "        f.write('\\n\\n')\n",
    "        f.write(output.stdout)\n",
    "    output.check_returncode()\n",
    "    print('\\n\\n\\n################# msmapper finished ###################\\n\\n\\n')"
   ],
   "id": "2ef7836778df780c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get miniumum hkl-step size",
   "id": "8570f0b684e28504"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bean = {\n",
    "    \"inputs\": inpath,\n",
    "    \"output\": TMP_NXS,\n",
    "    \"outputMode\": \"Coords_HKL\",\n",
    "    \"pixelIndexes\": [[0, 0, 0], [1, 1, 1], [2, 2, 2]],\n",
    "}\n",
    "json.dump(bean, open(TMP_BEAN, 'w'))\n",
    "msmapper(TMP_BEAN)\n",
    "\n",
    "print(f'\\nReading {TMP_NXS}')\n",
    "coords = h5py.File(TMP_NXS)['/processed/reciprocal_space/coordinates'][...]\n",
    "\n",
    "hkl_diff = np.abs(np.mean(np.diff(coords, axis=0), axis=0))\n",
    "print('\\n\\n***Results***')\n",
    "print('pixel step (h,k,l) = (%.2g, %.2g, %.2g)\\n\\n' % (hkl_diff[0], hkl_diff[1], hkl_diff[2]))\n"
   ],
   "id": "fe5fc198602c3ca6"
  },
  {
   "cell_type": "markdown",
   "id": "1b56a7ff-2300-4581-bc93-e52de844d018",
   "metadata": {},
   "source": [
    "## Run MSMapper"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5daa166-b6b1-41b6-aaa0-d19eea54e189",
   "metadata": {},
   "source": [
    "bean = {\n",
    "    \"inputs\": inpath,  # Filename of scan file\n",
    "    \"output\": outpath,  # Output filename - must be in processing directory, or somewhere you can write to\n",
    "    \"splitterName\": \"gaussian\",  # one of the following strings \"nearest\", \"gaussian\", \"negexp\", \"inverse\"\n",
    "    \"splitterParameter\": 2.0,  # splitter's parameter is distance to half-height of the weight function.\n",
    "    \"scaleFactor\": 2.0,  # the oversampling factor for each image\n",
    "    \"step\": step,  # a single value or list if 3 values and determines the lengths of each side of the voxels in the volume\n",
    "    #\"start\": start,  # location in HKL space of the bottom corner of the array.\n",
    "    #\"shape\": shape,  # size of the array to create for reciprocal space volume\n",
    "    \"outputMode\": \"Volume_HKL\",  # HKL or Q\n",
    "    \"toCrystalFrame\": True,  # for Volume_Q, use the crystal frame if True, or Lab frame otherwise\n",
    "    # \"thirdAxis\": np.array(third_axis).tolist(),  # [h, k, l] direction of Z-axis of voxel grid\n",
    "    # \"aziPlaneNormal\": np.array(azi_plane_normal).tolist(),  # [h, k, l] sets X-axis of voxel grid, normal to Z-axis\n",
    "    # \"region\": region,  # [sx, ex, sy, ey] region of interest on detector\n",
    "    \"monitorName\": normalisation,  # name of dataset to use to normalise results, e.g. 'rc'\n",
    "    \"correctPolarization\": False,  # apply polarisation correction\n",
    "    \"reduceToNonZero\": False if reduce_box == 'false' else reduce_box,  # True/False, if True, attempts to reduce the volume output\n",
    "}\n",
    "json.dump(bean, open(TMP_BEAN, 'w'))\n",
    "msmapper(TMP_BEAN)\n",
    "\n",
    "print(f\"File created {outpath}: {os.path.isfile(outpath)}\")\n",
    "print(f\"File size: {os.stat(outpath).st_size/1e6} MB\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45fedd70-cfc3-4c82-81fe-d3bdf0ff579e",
   "metadata": {},
   "source": [
    "## Load MSMapper output\n",
    "View the NeXus file [here](https://myhdf5.hdfgroup.org/) (drag and drop your file)."
   ]
  },
  {
   "cell_type": "code",
   "id": "959425a4-7c34-4b32-ac71-a7787a07401c",
   "metadata": {},
   "source": [
    "filename = os.path.basename(outpath)\n",
    "\n",
    "with h5py.File(outpath, 'r') as hdf:\n",
    "    def get_data(path, default=0):\n",
    "        dataset = hdf.get(path)\n",
    "        if dataset:\n",
    "            return dataset[...].squeeze()\n",
    "        return default\n",
    "\n",
    "    # the following are links to the original scan file\n",
    "    scan_command = hdf['/entry0/scan_command'].asstr()[()]  # str\n",
    "    crystal = hdf['/entry0/sample/name'].asstr()[()]  # str\n",
    "    temp = get_data('/entry0/instrument/temperature_controller/Tsample')  # float\n",
    "    unit_cell = get_data('/entry0/sample/unit_cell')  # 1D array, length 6\n",
    "    energy = get_data('/entry0/sample/beam/incident_energy')  # # float\n",
    "    ubmatrix = get_data('/entry0/sample/ub_matrix')  # 3D array, shape (3,3)\n",
    "    pixel_size = get_data('/entry0/instrument/pil3_100k/module/fast_pixel_direction', 0.1) # float, mm\n",
    "    detector_distance = get_data('/entry0/instrument/pil3_100k/transformations/origin_offset', 1000) # float, mm\n",
    "    # this is the processed data\n",
    "    haxis = hdf['/processed/reciprocal_space/h-axis'][...]  # 1D array, length n\n",
    "    kaxis = hdf['/processed/reciprocal_space/k-axis'][...]  # 1D array, length m\n",
    "    laxis = hdf['/processed/reciprocal_space/l-axis'][...]  # 1D array, length o\n",
    "    volume = hdf['/processed/reciprocal_space/volume'][...]  # 3D array, shape [n,m,o]\n",
    "\n",
    "print(f\"Loaded file: {filename} with volume shape: {volume.shape}\")\n",
    "\n",
    "print(f\"scan_command: {scan_command}\")\n",
    "print(f\"crystal: {crystal}\")\n",
    "print(f\"temp: {temp}\")\n",
    "print(f\"unit_cell: {unit_cell}\")\n",
    "print(f\"energy: {energy}\")\n",
    "print(f\"ubmatrix: {ubmatrix}\")\n",
    "print(f\"haxis: {haxis.min()}:{haxis.max()} {haxis.shape}\")\n",
    "print(f\"kaxis: {kaxis.min()}:{kaxis.max()} {kaxis.shape}\")\n",
    "print(f\"laxis: {laxis.min()}:{laxis.max()} {laxis.shape}\")\n",
    "print(f\"volume: {volume.shape}\")\n",
    "print(f\"pixel_size: {pixel_size}\")\n",
    "print(f\"detector_distance: {detector_distance}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# average angle subtended by each pixel\n",
    "solid_angle = pixel_size ** 2 / detector_distance ** 2  # sr\n",
    "print(f'Each pixel is normalised by the solid angle: {solid_angle: .4g} sr')\n",
    "\n",
    "volume = volume * solid_angle"
   ],
   "id": "70d50903bd085d4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot summed cuts\n",
    "plt.figure(figsize=(18, 8), dpi=60)\n",
    "title = f\"{filename} '{crystal}' {temp:.3g} K\\n{scan_command}\"\n",
    "plt.suptitle(title, fontsize=18)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(haxis, volume.sum(axis=1).sum(axis=1))\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [1,2]', fontsize=16)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(kaxis, volume.sum(axis=0).sum(axis=1))\n",
    "plt.xlabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [0,2]', fontsize=16)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(laxis, volume.sum(axis=0).sum(axis=0))\n",
    "plt.xlabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [0,1]', fontsize=16)\n",
    "\n",
    "# Plot summed images\n",
    "plt.figure(figsize=(18, 8), dpi=60)\n",
    "title = f\"{filename}\\n{crystal} {temp:.3g} K: {scan_command}\"\n",
    "plt.suptitle(title, fontsize=20)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.subplot(131)\n",
    "K, H = np.meshgrid(kaxis, haxis)\n",
    "plt.pcolormesh(H, K, volume.sum(axis=2), shading='auto')\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(132)\n",
    "L, H = np.meshgrid(laxis, haxis)\n",
    "plt.pcolormesh(H, L, volume.sum(axis=1), shading='auto')\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(133)\n",
    "L, K = np.meshgrid(laxis, kaxis)\n",
    "plt.pcolormesh(K, L, volume.sum(axis=0), shading='auto')\n",
    "plt.xlabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "plt.colorbar()\n",
    "plt.savefig(OUTPUT)\n",
    "plt.show()"
   ],
   "id": "f38c5da0c9586e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NXtransformations\n",
    "plot reciprocal space and instrument positions from NXtransformations"
   ],
   "id": "e1a47374d5420e37"
  },
  {
   "cell_type": "code",
   "id": "2d30db05-517a-4c0f-afc7-26f07b6cb72c",
   "metadata": {},
   "source": [
    "\n",
    "# from i16_msmapper.nx_transformations import NXScan\n",
    "#\n",
    "# with h5py.File(inpath[0]) as nxs:\n",
    "#     scan = NXScan(nxs)\n",
    "#     scan.plot_wavevectors()\n",
    "#\n",
    "#     scan.plot_instrument()\n",
    "#\n",
    "#     plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbaba31b-2948-41ae-a17f-8cc3b6a6775e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
