{
 "cells": [
  {
   "cell_type": "code",
   "id": "41b9322b-f87f-4aad-ad18-8274890181ec",
   "metadata": {},
   "source": [
    "datadir = \"\"\n",
    "inpath = \"/dls/science/groups/das/ExampleData/NeXus/newnexuswriter2024/i16/i16_nexus_test_04Feb25/1078060.nxs\"\n",
    "outpath = \"/dls/science/groups/das/ExampleData/NeXus/newnexuswriter2024/i16/i16_nexus_test_04Feb25/1078060_remap_test.nxs\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dec41e54-cc52-4a63-9bbb-29eba933c5ec",
   "metadata": {},
   "source": [
    "# Run MSMapper and Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "db850d5c-175d-4687-bfc3-13ba82e47d46",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hdfmap\n",
    "from i16_msmapper import mapper_runner\n",
    "\n",
    "# set the location of msmapper\n",
    "MSMAPPER = '/tmp/msmapper/msmapper'\n",
    "mapper_runner.SHELL_CMD = MSMAPPER + \" -bean %s\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b56a7ff-2300-4581-bc93-e52de844d018",
   "metadata": {},
   "source": [
    "## Run MSMapper"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5daa166-b6b1-41b6-aaa0-d19eea54e189",
   "metadata": {},
   "source": [
    "mapper_runner.run_msmapper(\n",
    "    input_files=[inpath],\n",
    "    output_file=outpath\n",
    ")\n",
    "print(f\"File created {outpath}: {os.path.isfile(outpath)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45fedd70-cfc3-4c82-81fe-d3bdf0ff579e",
   "metadata": {},
   "source": [
    "## Load MSMapper output"
   ]
  },
  {
   "cell_type": "code",
   "id": "959425a4-7c34-4b32-ac71-a7787a07401c",
   "metadata": {},
   "source": [
    "import h5py\n",
    "filename = os.path.basename(outpath)\n",
    "\n",
    "with h5py.File(outpath, 'r') as hdf:\n",
    "    # the following are links to the original scan file\n",
    "    scan_command = hdf['/entry0/scan_command'].asstr()[()]  # str\n",
    "    crystal = hdf['/entry0/sample/name'].asstr()[()]  # str\n",
    "    temp = hdf['/entry0/instrument/temperature_controller/Tsample'][()]  # float\n",
    "    unit_cell = np.reshape(hdf['/entry0/sample/unit_cell'], -1)  # 1D array, length 6\n",
    "    energy = hdf['/entry0/sample/beam/incident_energy'][()]  # # float\n",
    "    ubmatrix = hdf['/entry0/sample/ub_matrix'][0]  # 3D array, shape (3,3)\n",
    "    # this is the processed data\n",
    "    haxis = hdf['/processed/reciprocal_space/h-axis'][()]  # 1D array, length n\n",
    "    kaxis = hdf['/processed/reciprocal_space/k-axis'][()]  # 1D array, length m\n",
    "    laxis = hdf['/processed/reciprocal_space/l-axis'][()]  # 1D array, length o\n",
    "    volume = hdf['/processed/reciprocal_space/volume'][()]  # 3D array, shape [n,m,o]\n",
    "    # detector parameters\n",
    "    pixel_size = hdf['/entry0/instrument/pil3_100k/module/fast_pixel_direction'][()] # float, mm\n",
    "    detector_distance = hdf['/entry/instrument/pil3_100k/transformations/origin_offset'][()] # float, mm\n",
    "\n",
    "print(f\"Loaded file: {filename} with volume shape: {volume.shape}\")\n",
    "\n",
    "# average angle subtended by each pixel\n",
    "solid_angle = pixel_size ** 2 / detector_distance ** 2  # sr\n",
    "print(f'Each pixel is normalised by the solid angle: {solid_angle: .4g} sr')\n",
    "\n",
    "volume = volume * solid_angle\n",
    "\n",
    "# Plot summed cuts\n",
    "plt.figure(figsize=[18, 8], dpi=60)\n",
    "title = f\"{filename} '{crystal}' {temp:.3g} K\\n{scan_command}\"\n",
    "plt.suptitle(title, fontsize=18)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(haxis, volume.sum(axis=1).sum(axis=1))\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [1,2]', fontsize=16)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(kaxis, volume.sum(axis=0).sum(axis=1))\n",
    "plt.xlabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [0,2]', fontsize=16)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(laxis, volume.sum(axis=0).sum(axis=0))\n",
    "plt.xlabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('sum axes [0,1]', fontsize=16)\n",
    "\n",
    "# Plot summed images\n",
    "plt.figure(figsize=[18, 8], dpi=60)\n",
    "title = f\"{filename}\\n{crystal} {temp:.3g} K: {scan_command}\"\n",
    "plt.suptitle(title, fontsize=20)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.subplot(131)\n",
    "K, H = np.meshgrid(kaxis, haxis)\n",
    "plt.pcolormesh(H, K, volume.sum(axis=2), shading='auto')\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(132)\n",
    "L, H = np.meshgrid(laxis, haxis)\n",
    "plt.pcolormesh(H, L, volume.sum(axis=1), shading='auto')\n",
    "plt.xlabel('h-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(133)\n",
    "L, K = np.meshgrid(laxis, kaxis)\n",
    "plt.pcolormesh(K, L, volume.sum(axis=0), shading='auto')\n",
    "plt.xlabel('k-axis (r.l.u.)', fontsize=16)\n",
    "plt.ylabel('l-axis (r.l.u.)', fontsize=16)\n",
    "plt.axis('image')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b31152bd-f382-461c-ba55-4f4773b3b0ca",
   "metadata": {},
   "source": [
    "# NXtransformations\n",
    "code taken from https://github.com/DanPorter/i16_diffractometer "
   ]
  },
  {
   "cell_type": "code",
   "id": "f5c2e56f-d2ee-4328-9d5e-c857832c0bff",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def photon_wavelength(energy_kev):\n",
    "    \"\"\"\n",
    "    Converts energy in keV to wavelength in A\n",
    "     wavelength_a = photon_wavelength(energy_kev)\n",
    "     lambda [A] = h*c/E = 12.3984 / E [keV]\n",
    "    \"\"\"\n",
    "    return 12.3984 / energy_kev\n",
    "\n",
    "\n",
    "def photon_energy(wavelength_a):\n",
    "    \"\"\"\n",
    "    Converts wavelength in A to energy in keV\n",
    "     energy_kev = photon_energy(wavelength_a)\n",
    "     Energy [keV] = h*c/L = 12.3984 / lambda [A]\n",
    "    \"\"\"\n",
    "    return 12.3984 / wavelength_a\n",
    "\n",
    "\n",
    "def wavevector(wavelength_a):\n",
    "    \"\"\"Return wavevector = 2pi/lambda\"\"\"\n",
    "    return 2 * np.pi / wavelength_a\n",
    "\n",
    "\n",
    "def bmatrix(a, b=None, c=None, alpha=90., beta=90., gamma=90.):\n",
    "    \"\"\"\n",
    "    Calculate the B matrix as defined in Busing&Levy Acta Cyst. 22, 457 (1967)\n",
    "    Creates a matrix to transform (hkl) into a cartesian basis:\n",
    "        (qx,qy,qz)' = B.(h,k,l)'       (where ' indicates a column vector)\n",
    "     \n",
    "    The B matrix is related to the reciprocal basis vectors:\n",
    "        (astar, bstar, cstar) = 2 * np.pi * B.T\n",
    "    Where cstar is defined along the z axis\n",
    "\n",
    "    The B matrix is related to the real-space unit vectors:\n",
    "        (A, B, C) = B^-1 = inv(B)\n",
    " \n",
    "    :param a: lattice parameter a in Anstroms\n",
    "    :param b: lattice parameter b in Anstroms\n",
    "    :param c: lattice parameter c in Anstroms\n",
    "    :param alpha: lattice angle alpha in degrees\n",
    "    :param beta: lattice angle beta in degrees\n",
    "    :param gamma: lattice angle gamma in degrees\n",
    "    :returns: [3x3] array B matrix in inverse-Angstroms (no 2pi)\n",
    "    \"\"\"\n",
    "    if b is None:\n",
    "        b = a\n",
    "    if c is None:\n",
    "        c = a\n",
    "    alpha1 = np.deg2rad(alpha)\n",
    "    alpha2 = np.deg2rad(beta)\n",
    "    alpha3 = np.deg2rad(gamma)\n",
    " \n",
    "    beta1 = np.arccos((np.cos(alpha2)*np.cos(alpha3)-np.cos(alpha1))/(np.sin(alpha2)*np.sin(alpha3)))\n",
    "    beta2 = np.arccos((np.cos(alpha1)*np.cos(alpha3)-np.cos(alpha2))/(np.sin(alpha1)*np.sin(alpha3)))\n",
    "    beta3 = np.arccos((np.cos(alpha1)*np.cos(alpha2)-np.cos(alpha3))/(np.sin(alpha1)*np.sin(alpha2)))\n",
    " \n",
    "    b1 = 1 / (a * np.sin(alpha2) * np.sin(beta3))\n",
    "    b2 = 1 / (b * np.sin(alpha3) * np.sin(beta1))\n",
    "    b3 = 1 / (c * np.sin(alpha1) * np.sin(beta2))\n",
    " \n",
    "    c1 = b1 * b2 * np.cos(beta3)\n",
    "    c2 = b1 * b3 * np.cos(beta2)\n",
    "    c3 = b2 * b3 * np.cos(beta1)\n",
    " \n",
    "    bm = np.array([\n",
    "        [b1, b2 * np.cos(beta3), b3 * np.cos(beta2)],\n",
    "        [0, b2 * np.sin(beta3), -b3 * np.sin(beta2)*np.cos(alpha1)],\n",
    "        [0, 0, 1/c]\n",
    "    ])\n",
    "    return bm \n",
    "\n",
    "\n",
    "def norm_vector(vector, min_mag=0.001):\n",
    "    mag = np.linalg.norm(vector)\n",
    "    if mag < min_mag:\n",
    "        mag = 1.\n",
    "    return np.divide(vector, mag)\n",
    "\n",
    "\n",
    "def rot_matrix(angle_rad: float, axis=(0, 0, 1)):\n",
    "    \"\"\"\n",
    "    Generate rotation matrix about arbitary axis\n",
    "    https://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle\n",
    "    \"\"\"\n",
    "    axis = norm_vector(axis)\n",
    "    ux, uy, uz = axis\n",
    "    c = np.cos(angle_rad)\n",
    "    s = np.sin(angle_rad)\n",
    "    c1 = 1 - c\n",
    "    r = np.array([\n",
    "        [\n",
    "            (ux * ux * c1) + c,\n",
    "            (uy * ux * c1) - uz * s,\n",
    "            (uz * ux * c1) + uy * s\n",
    "        ],\n",
    "        [\n",
    "            (ux * uy * c1) + uz * s,\n",
    "            (uy * uy * c1) + c,\n",
    "            (uz * uy * c1) - ux * s,\n",
    "        ],\n",
    "        [\n",
    "            (ux * uz * c1) - uy * s,\n",
    "            (uy * uz * c1) + ux * s,\n",
    "            (uz * uz * c1) + c,\n",
    "        ]\n",
    "    ])\n",
    "    return r\n",
    "\n",
    "\n",
    "def rotation_t_matrix(value=0.0, vector=(0, 0, 1), offset=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Create 4x4 transformation matrix including a rotation\n",
    "    \"\"\"\n",
    "    t = np.eye(4)\n",
    "    t[:3, :3] = rot_matrix(angle_rad=value, axis=vector)\n",
    "    t[:3, 3] = offset\n",
    "    return t\n",
    "\n",
    "\n",
    "def translation_t_matrix(value=0.0, vector=(0, 0, 1), offset=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Create 4x4 transformation matrix including a translation\n",
    "    \"\"\"\n",
    "    t = np.eye(4)\n",
    "    translation = value * np.reshape(vector, 3) + np.reshape(offset, 3)\n",
    "    t[:3, 3] = translation\n",
    "    return t\n",
    "\n",
    "\n",
    "def rotate_by_matrix(xyz, angle_deg=0.0, axis=(0, 0, 1)):\n",
    "    r = rot_matrix(np.deg2rad(angle_deg), axis)\n",
    "    xyz = np.reshape(xyz, (-1, 3))\n",
    "    return np.dot(r, xyz.T).T\n",
    "\n",
    "\n",
    "def transform_by_t_matrix(xyz, t_matrix):\n",
    "    xyz = np.reshape(xyz, (-1, 3))\n",
    "    return (np.dot(t_matrix[:3, :3], xyz.T) + t_matrix[:3, 3:]).T\n",
    "\n",
    "\n",
    "####### nexus_transformations.py ########\n",
    "\n",
    "\n",
    "METERS = {  # conversion to meters\n",
    "    'km': 1e3, 'm': 1, 'cm': 0.1, 'mm': 1e-3,\n",
    "    'um': 1e-6, 'μm': 1e-6, 'nm': 1e-9,\n",
    "    'A': 1e-10, 'Å': 1e-10\n",
    "}\n",
    "\n",
    "NX_CLASS = 'NX_class'\n",
    "NX_DEFAULT = 'default'\n",
    "NX_DEPON = 'depends_on'\n",
    "NX_VECTOR = 'vector'\n",
    "NX_OFFSET = 'offset'\n",
    "NX_TTYPE = 'transformation_type'\n",
    "NX_TROT = 'rotation'\n",
    "NX_TTRAN = 'translation'\n",
    "NX_UNITS = 'units'\n",
    "NX_WL = 'incident_wavelength'\n",
    "NX_EN = 'incident_energy'\n",
    "NX_ENTRY = 'NXentry'\n",
    "NX_INST = 'NXinstrument'\n",
    "NX_DET = 'NXdetector'\n",
    "NX_SAMPLE = 'NXsample'\n",
    "NX_MODULE = 'NXdetector_module'\n",
    "NX_BEAM = 'NXbeam'\n",
    "NX_SAMPLE_NAME = 'name'\n",
    "NX_SAMPLE_UC = 'unit_cell'\n",
    "NX_SAMPLE_OM = 'orientation_matrix'\n",
    "NX_SAMPLE_UB = 'ub_matrix'\n",
    "NX_MODULE_ORIGIN = 'data_origin'\n",
    "NX_MODULE_SIZE = 'data_size'\n",
    "NX_MODULE_OFFSET = 'module_offset'\n",
    "NX_MODULE_FAST = 'fast_pixel_direction'\n",
    "NX_MODULE_SLOW = 'slow_pixel_direction'\n",
    "\n",
    "\n",
    "def check_nexus_class(hdf_group: h5py.Group, nxclass: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if hdf_group is a certain NX_class\n",
    "    :param hdf_group: hdf or nexus group object\n",
    "    :param nxclass: str name in NX_class attribute\n",
    "    :return: True/False\n",
    "    \"\"\"\n",
    "    return (hdf_group and\n",
    "            (group_class := hdf_group.attrs.get(NX_CLASS)) is not None and\n",
    "            (group_class.decode() if isinstance(group_class, bytes) else group_class) == nxclass)\n",
    "\n",
    "\n",
    "def nx_first_nxclass(group: h5py.File | h5py.Group, nxclass: str) -> str:\n",
    "    \"\"\"\n",
    "    Find first object within group that has correct NX_class attribute\n",
    "    :param group:\n",
    "    :param nxclass:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if NX_DEFAULT in group.attrs and check_nexus_class(group.get(path := group.attrs[NX_DEFAULT]), nxclass):\n",
    "        return path.decode() if isinstance(path, bytes) else path\n",
    "    return next(path for path in group if check_nexus_class(group.get(path), nxclass))\n",
    "\n",
    "\n",
    "def get_depends_on(path: str, hdf_file: h5py.File) -> str:\n",
    "    \"\"\"\n",
    "    Returns 'depends_on' path from this group or dataset\n",
    "    The returned path will point to a dataset, based on NeXus rules\n",
    "    :param path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    obj = hdf_file[path]\n",
    "    if NX_DEPON in obj.attrs:\n",
    "        do_path = obj.attrs[NX_DEPON]\n",
    "    elif isinstance(obj, h5py.Group) and NX_DEPON in obj:\n",
    "        do_path = obj[NX_DEPON][()]\n",
    "    else:\n",
    "        return '.'\n",
    "\n",
    "    if do_path in hdf_file:\n",
    "        return do_path.decode() if isinstance(do_path, bytes) else do_path\n",
    "    # walk up tree to find relative file path\n",
    "    while (isinstance(obj, h5py.Dataset) or do_path not in obj) and obj != obj.file:\n",
    "        obj = obj.parent\n",
    "    return obj[do_path].name if do_path in obj else '.'\n",
    "\n",
    "\n",
    "def get_dataset_value(path: str, group: h5py.Group | h5py.File, default):\n",
    "    \"\"\"\n",
    "    Get value from dataset in group, or return default\n",
    "    :param path: hdf path of dataset in group\n",
    "    :param group: hdf group\n",
    "    :param default: returned if path doesn't exist\n",
    "    :return: group[path][()]\n",
    "    \"\"\"\n",
    "    if path in group:\n",
    "        dataset = group[path]\n",
    "        if np.issubdtype(dataset, np.number):\n",
    "            return np.squeeze(dataset[()])\n",
    "        return dataset.asstr()[()]\n",
    "    return default\n",
    "\n",
    "\n",
    "def nx_depends_on_chain(path: str, hdf_file: h5py.File) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns list of paths in a transformation chain, linked by 'depends_on'\n",
    "    :param path: hdf path of initial dataset or group\n",
    "    :param hdf_file: Nexus file object\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    depends_on = get_depends_on(path, hdf_file)\n",
    "    out = []\n",
    "    if depends_on != '.':\n",
    "        out.append(depends_on)\n",
    "        out.extend(nx_depends_on_chain(depends_on, hdf_file))\n",
    "    return out\n",
    "\n",
    "\n",
    "def nx_direction(path: str, hdf_file: h5py.File) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return a unit-vector direction from a dataset\n",
    "    :param path: hdf path of NXtransformation path or component group with 'depends_on'\n",
    "    :param hdf_file: Nexus file object\n",
    "    :return: unit-vector array\n",
    "    \"\"\"\n",
    "    depends_on = get_depends_on(path, hdf_file)\n",
    "    if depends_on == '.':\n",
    "        dataset = hdf_file[path]\n",
    "    else:\n",
    "        dataset = hdf_file[depends_on]\n",
    "\n",
    "    vector = np.asarray(dataset.attrs.get(NX_VECTOR, (0, 0, 0)))\n",
    "    return norm_vector(vector)\n",
    "\n",
    "\n",
    "def nx_transformations_max_size(path: str, hdf_file: h5py.File) -> int:\n",
    "    \"\"\"\n",
    "    Return the maximum dataset size from a chain of transformations\n",
    "    :param path: hdf dataset path of NX transformation, or group containing 'depends_on'\n",
    "    :param hdf_file: Nexus file object\n",
    "    :return: int : largest dataset.size\n",
    "    \"\"\"\n",
    "    dataset = hdf_file[path]\n",
    "    dataset_size = dataset.size if isinstance(dataset, h5py.Dataset) else 0\n",
    "    depends_on = get_depends_on(path, hdf_file)\n",
    "    if depends_on != '.':\n",
    "        size = nx_transformations_max_size(depends_on, hdf_file)\n",
    "        return size if size > dataset_size else dataset_size\n",
    "    return dataset_size\n",
    "\n",
    "\n",
    "def nx_transformations(path: str, index: int, hdf_file: h5py.File, print_output=False) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create list of 4x4 transformation matrices matching transformations along an NXtransformations chain\n",
    "    :param path: str hdf path of the first point in the chain (Group or Dataset)\n",
    "    :param index: int index of point in scan\n",
    "    :param hdf_file: Nexus file object\n",
    "    :param print_output: bool, if true the operations will be printed\n",
    "    :return: list of 4x4 arrays [T1, T2, T3, ... Tn]\n",
    "    \"\"\"\n",
    "    dataset = hdf_file[path]\n",
    "    depends_on = get_depends_on(path, hdf_file)\n",
    "    if print_output:\n",
    "        print(f\"{dataset}, depends on: {depends_on}\")\n",
    "\n",
    "    if isinstance(dataset, h5py.Group):\n",
    "        return nx_transformations(depends_on, index, hdf_file, print_output)\n",
    "\n",
    "    this_index = index if dataset.size > 1 else 0\n",
    "    value = dataset[np.unravel_index(this_index, dataset.shape)]\n",
    "\n",
    "    transformation_type = dataset.attrs.get(NX_TTYPE, b'').decode()\n",
    "    vector = np.array(dataset.attrs.get(NX_VECTOR, (1, 0, 0)))\n",
    "    offset = dataset.attrs.get(NX_OFFSET, (0, 0, 0))\n",
    "    units = dataset.attrs.get(NX_UNITS, b'').decode()\n",
    "\n",
    "    if transformation_type == NX_TROT:\n",
    "        if print_output:\n",
    "            print(f\"Rotating about {vector} by {value} {units}  | {path}\")\n",
    "        if units == 'deg':\n",
    "            value = np.deg2rad(value)\n",
    "        elif units != 'rad':\n",
    "            value = np.deg2rad(value)\n",
    "            print(f\"Warning: Incorrect rotation units: '{units}'\")\n",
    "        matrix = rotation_t_matrix(value, vector, offset)\n",
    "    elif transformation_type == NX_TTRAN:\n",
    "        if print_output:\n",
    "            print(f\"Translating along {vector} by {value} {units}  | {path}\")\n",
    "        if units in METERS:\n",
    "            unit_multiplier = METERS[units]\n",
    "        else:\n",
    "            unit_multiplier = 1.0\n",
    "            print(f\"Warning: unknown translation untis: {units}\")\n",
    "        value = value * unit_multiplier * 1000  # distance in mm\n",
    "        matrix = translation_t_matrix(value, vector, offset)\n",
    "    else:\n",
    "        if print_output:\n",
    "            print(f\"transformation type of '{path}' not recognized: '{transformation_type}'\")\n",
    "        matrix = np.eye(4)\n",
    "\n",
    "    if depends_on == '.':  # end chain\n",
    "        return [matrix]\n",
    "    return [matrix] + nx_transformations(depends_on, index, hdf_file, print_output)\n",
    "\n",
    "\n",
    "def nx_transformations_matrix(path: str, index: int, hdf_file: h5py.File) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Combine chain of transformation operations into single matrix\n",
    "    :param path: str hdf path of the first point in the chain (Group or Dataset)\n",
    "    :param index: int index of point in scan\n",
    "    :param hdf_file: Nexus file object\n",
    "    :return: 4x4 array\n",
    "    \"\"\"\n",
    "    matrices = nx_transformations(path, index, hdf_file)\n",
    "    # Combine the transformations in reverse\n",
    "    return np.linalg.multi_dot(matrices[::-1])  # multiply transformations Tn..T3.T2.T1\n",
    "\n",
    "\n",
    "def nx_transform_vector(xyz, path: str, index: int, hdf_file: h5py.File) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transform a vector or position [x, y, z] by an NXtransformations chain\n",
    "    :param xyz: 3D coordinates, n*3 [[x, y, z], ...]\n",
    "    :param path: hdf path of first object in NXtransformations chain\n",
    "    :param index: int index of point in scan\n",
    "    :param hdf_file: Nexus file object\n",
    "    :return: n*3 array([[x, y, z], ...]) transformed by operations\n",
    "    \"\"\"\n",
    "    xyz = np.reshape(xyz, (-1, 3))\n",
    "    t_matrix = nx_transformations_matrix(path, index, hdf_file)\n",
    "    return (np.dot(t_matrix[:3, :3], xyz.T) + t_matrix[:3, 3:]).T\n",
    "\n",
    "\n",
    "def nx_beam_energy(beam: h5py.Group):\n",
    "    \"\"\"\n",
    "    Return beam energy in keV and wavelength in A\n",
    "    :param beam: Nexus NXbeam group\n",
    "    :return: incident_energy, incident_wavelength\n",
    "    \"\"\"\n",
    "    if NX_WL in beam:\n",
    "        dataset = beam[NX_WL]\n",
    "        units = dataset.attrs.get(NX_UNITS, b'nm').decode()\n",
    "        wl = dataset[()]\n",
    "        if units.lower() in METERS:\n",
    "            wl = wl * METERS[units] * 1e-10  # wavelength in Angstroms\n",
    "        else:\n",
    "            print(f\"Warning: unknown translation untis: {units}\")\n",
    "        return photon_energy(wl), wl\n",
    "    elif NX_EN in beam:\n",
    "        dataset = beam[NX_WL]\n",
    "        units = dataset.attrs.get(NX_UNITS, b'ev').decode()\n",
    "        en = dataset[()]\n",
    "        if units.lower() == 'ev':\n",
    "            en = en / 1000.  # wavelength in keV\n",
    "        return en, photon_wavelength(en)\n",
    "    else:\n",
    "        raise KeyError(f\"{beam} contains no '{NX_WL}' or '{NX_EN}'\")\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "class NXBeam:\n",
    "    \"\"\"\n",
    "    NXbeam object\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, hdf_file: h5py.File):\n",
    "        self.file = hdf_file\n",
    "        self.path = path\n",
    "        self.beam = hdf_file[path]\n",
    "\n",
    "        self.direction = nx_direction(path, hdf_file)\n",
    "        self.en, self.wl = self.energy_wavelength()\n",
    "        self.wv = wavevector(self.wl)\n",
    "        self.incident_wavevector = self.wv * self.direction\n",
    "\n",
    "    def energy_wavelength(self):\n",
    "        \"\"\"\n",
    "        Return beam energy in keV and wavelength in A\n",
    "        :return: incident_energy, incident_wavelength\n",
    "        \"\"\"\n",
    "        if NX_WL in self.beam:\n",
    "            dataset = self.beam[NX_WL]\n",
    "            units = dataset.attrs.get(NX_UNITS, b'nm').decode()\n",
    "            wl = dataset[()]\n",
    "            if units == 'nm':\n",
    "                wl = 10 * wl  # wavelength in Angstroms\n",
    "            return photon_energy(wl), wl\n",
    "        elif NX_EN in self.beam:\n",
    "            dataset = self.beam[NX_WL]\n",
    "            units = dataset.attrs.get(NX_UNITS, b'ev').decode()\n",
    "            en = dataset[()]\n",
    "            if units.lower() == 'ev':\n",
    "                en = en / 1000.  # wavelength in keV\n",
    "            return en, photon_wavelength(en)\n",
    "        else:\n",
    "            raise KeyError(f\"{self.beam} contains no '{NX_WL}' or '{NX_EN}'\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NXBeam({self.beam})\"\n",
    "\n",
    "\n",
    "class NXSsample:\n",
    "    \"\"\"\n",
    "    NXsample object\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, hdf_file: h5py.File):\n",
    "        self.file = hdf_file\n",
    "        self.path = path\n",
    "        self.sample = hdf_file[path]\n",
    "\n",
    "        self.name = get_dataset_value(NX_SAMPLE_NAME, self.sample, 'none')\n",
    "        self.unit_cell = get_dataset_value(NX_SAMPLE_UC, self.sample, np.array([1., 1, 1, 90, 90, 90]))\n",
    "        self.orientation_matrix = get_dataset_value(NX_SAMPLE_OM, self.sample, np.eye(3))\n",
    "        self.ub_matrix = get_dataset_value(NX_SAMPLE_UB, self.sample, bmatrix(*self.unit_cell))\n",
    "\n",
    "        self.size = nx_transformations_max_size(path, hdf_file)\n",
    "        self.transforms = [\n",
    "            nx_transformations_matrix(path, n, hdf_file)\n",
    "            for n in range(self.size)\n",
    "        ]  # list of 4x4 transformation matrices\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NXSsample({self.sample})\"\n",
    "\n",
    "    def hkl2q(self, hkl: Tuple[float, float, float] | np.ndarray):\n",
    "        \"\"\"\n",
    "        Returns wavecector direction for given hkl\n",
    "        :param hkl: Miller indices, in units of reciprocal lattice vectors\n",
    "        :return: Q position in inverse Angstroms\n",
    "        \"\"\"\n",
    "        hkl = np.reshape(hkl, (-1, 3))\n",
    "        z = self.transforms[0][:3, :3]\n",
    "        ub = 2 * np.pi * self.ub_matrix\n",
    "        return np.dot(z, np.dot(ub, hkl.T)).T\n",
    "\n",
    "\n",
    "class NXDetectorModule:\n",
    "    \"\"\"\n",
    "    NXdetector_module object\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, hdf_file: h5py.File):\n",
    "        self.file = hdf_file\n",
    "        self.path = path\n",
    "        self.module = hdf_file[path]\n",
    "\n",
    "        self.data_origin = get_dataset_value(NX_MODULE_ORIGIN, self.module, np.array([0, 0]))\n",
    "        self.data_size = get_dataset_value(NX_MODULE_SIZE, self.module, np.array([1, 1]))\n",
    "\n",
    "        self.module_offset_path = f\"{self.path}/{NX_MODULE_OFFSET}\"\n",
    "        self.fast_pixel_direction_path = f\"{self.path}/{NX_MODULE_FAST}\"\n",
    "        self.slow_pixel_direction_path = f\"{self.path}/{NX_MODULE_SLOW}\"\n",
    "\n",
    "        self.size = nx_transformations_max_size(self.module_offset_path, hdf_file)\n",
    "        self.offset_transforms = [\n",
    "            nx_transformations_matrix(self.module_offset_path, n, hdf_file)\n",
    "            for n in range(self.size)\n",
    "        ]  # list of 4x4 transformation matrices\n",
    "        self.fast_transforms = [\n",
    "            nx_transformations_matrix(self.fast_pixel_direction_path, n, hdf_file)\n",
    "            for n in range(self.size)\n",
    "        ]  # list of 4x4 transformation matrices\n",
    "        self.slow_transforms = [\n",
    "            nx_transformations_matrix(self.slow_pixel_direction_path, n, hdf_file)\n",
    "            for n in range(self.size)\n",
    "        ]  # list of 4x4 transformation matrices\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NXDetectorModule({self.module})\"\n",
    "\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Return scan shape of module\n",
    "            (n, i, j)\n",
    "        Where:\n",
    "            n = frames in scan\n",
    "            i = pixels along slow axis\n",
    "            j = pixels along fast axis\n",
    "        \"\"\"\n",
    "        return self.size, self.data_size[0], self.data_size[1]\n",
    "\n",
    "    def pixel_wavevector(self, point: Tuple[int, int, int], wavelength_a) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return wavevector of pixel\n",
    "        :param point: (n, i, j) == (frame, slow_axis_pixel, fast_axis_pixel)\n",
    "        :param wavelength_a: wavelength in Angstrom\n",
    "        :return: [dx, dy, dz] unit vector\n",
    "        \"\"\"\n",
    "        return wavevector(wavelength_a) * self.pixel_direction(point)\n",
    "\n",
    "    def pixel_direction(self, point: Tuple[int, int, int]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return direction of pixel\n",
    "        :param point: (n, i, j) == (frame, slow_axis_pixel, fast_axis_pixel)\n",
    "        :return: [dx, dy, dz] unit vector\n",
    "        \"\"\"\n",
    "        return norm_vector(self.pixel_position(point))\n",
    "\n",
    "    def pixel_position(self, point: Tuple[int, int, int]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return position of pixel (n, i, j)\n",
    "            n = frame in scan\n",
    "            i = pixel along slow axis\n",
    "            j = pixel along fast axis\n",
    "        \"\"\"\n",
    "        index, ii, jj = point\n",
    "\n",
    "        module_origin = transform_by_t_matrix([0, 0, 0], self.offset_transforms[index])\n",
    "        fast_pixel = transform_by_t_matrix([0, 0, 0], self.fast_transforms[index])\n",
    "        slow_pixel = transform_by_t_matrix([0, 0, 0], self.slow_transforms[index])\n",
    "\n",
    "        fast_direction = fast_pixel - module_origin\n",
    "        slow_direction = slow_pixel - module_origin\n",
    "        return np.squeeze(ii * slow_direction + jj * fast_direction + module_origin)\n",
    "\n",
    "    def corners(self, frame: int) -> np.ndarray:\n",
    "        shape = self.shape()\n",
    "        corners = np.vstack([\n",
    "            self.pixel_position((frame, 0, 0)),  # module origin\n",
    "            self.pixel_position((frame, int(shape[1]), 0)),  # module origin + slow pixels\n",
    "            self.pixel_position((frame, int(shape[1]), int(shape[2]))),  # o + slow + fast\n",
    "            self.pixel_position((frame, 0, int(shape[2]))),  # o + fast\n",
    "            self.pixel_position((frame, 0, 0)),  # module origin\n",
    "        ])\n",
    "        return corners\n",
    "\n",
    "\n",
    "class NXDetector:\n",
    "    \"\"\"\n",
    "    NXdetector object\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str, hdf_file: h5py.File):\n",
    "        self.file = hdf_file\n",
    "        self.path = path\n",
    "        self.detector = hdf_file[path]\n",
    "        self.size = nx_transformations_max_size(path, hdf_file)\n",
    "        self.position = nx_transform_vector((0, 0, 0), path, self.size // 2, hdf_file).squeeze()\n",
    "\n",
    "        self.modules = [\n",
    "            NXDetectorModule(f\"{self.path}/{p}\", hdf_file)\n",
    "            for p, obj in self.detector.items()\n",
    "            if obj.attrs.get(NX_CLASS) == NX_MODULE.encode()\n",
    "        ]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NXDetector({self.detector}) with {len(self.modules)} modules\"\n",
    "\n",
    "\n",
    "class NXScan:\n",
    "    \"\"\"\n",
    "    NXScan object\n",
    "    \"\"\"\n",
    "    def __init__(self, hdf_file: h5py.File):\n",
    "        self.file = hdf_file\n",
    "\n",
    "        self.entry = hdf_file[nx_first_nxclass(hdf_file, NX_ENTRY)]\n",
    "        self.instrument = self.entry[nx_first_nxclass(self.entry, NX_INST)]\n",
    "\n",
    "        self.detectors = [\n",
    "            NXDetector(f\"{self.instrument.name}/{p}\", hdf_file)\n",
    "            for p, obj in self.instrument.items()\n",
    "            if obj.attrs.get(NX_CLASS) == NX_DET.encode()\n",
    "        ]\n",
    "        self.components = [\n",
    "            obj for obj in self.instrument.values()\n",
    "            if isinstance(obj, h5py.Group) and 'depends_on' in obj\n",
    "        ]\n",
    "        self.component_positions = {\n",
    "            obj.name.split('/')[-1]: nx_transform_vector((0, 0, 0), obj.name, 0, hdf_file).squeeze()\n",
    "            for obj in self.components\n",
    "        }\n",
    "        self.component_positions['sample'] = np.array([0, 0, 0])\n",
    "\n",
    "        sample_obj = self.entry[nx_first_nxclass(self.entry, NX_SAMPLE)]\n",
    "        self.sample = NXSsample(sample_obj.name, hdf_file)\n",
    "        beam_obj = sample_obj[nx_first_nxclass(sample_obj, NX_BEAM)]\n",
    "        self.beam = NXBeam(beam_obj.name, hdf_file)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NXScan({self.file})\"\n",
    "\n",
    "    def shape(self):\n",
    "        detector_module = self.detectors[0].modules[0]\n",
    "        return detector_module.shape()\n",
    "\n",
    "    def detector_q(self, point: Tuple[int, int, int] = (0, 0, 0)):\n",
    "        wavelength = self.beam.wl\n",
    "        ki = self.beam.incident_wavevector\n",
    "        detector_module = self.detectors[0].modules[0]\n",
    "        kf = detector_module.pixel_wavevector(point, wavelength)\n",
    "        return kf - ki\n",
    "\n",
    "    def hkl(self, point: Tuple[int, int, int] = (0, 0, 0)):\n",
    "        q = self.detector_q(point)\n",
    "        z = self.sample.transforms[point[0]][:3, :3]\n",
    "        ub = 2 * np.pi * self.sample.ub_matrix\n",
    "\n",
    "        inv_ub = np.linalg.inv(ub)\n",
    "        inv_z = np.linalg.inv(z)\n",
    "\n",
    "        hphi = np.dot(inv_z, q)\n",
    "        return np.dot(inv_ub, hphi).T\n",
    "\n",
    "    def hkl2q(self, hkl: Tuple[float, float, float] | np.ndarray):\n",
    "        \"\"\"\n",
    "        Returns wavecector direction for given hkl\n",
    "        :param hkl: Miller indices, in units of reciprocal lattice vectors\n",
    "        :return: Q position in inverse Angstroms\n",
    "        \"\"\"\n",
    "        return self.sample.hkl2q(hkl)\n",
    "\n",
    "    def plot_instrument(self, figsize=[16, 6], dpi=100):\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "        instrument_name = get_dataset_value('name', self.instrument, 'no name')\n",
    "        max_distance = max([np.linalg.norm(position) for position in self.component_positions.values()])\n",
    "        max_position = max_distance * self.beam.direction\n",
    "\n",
    "        ax.plot([-max_position[0], 0], [-max_position[2], 0], [-max_position[1], 0], 'k-')  # beam\n",
    "        beam_cont = np.linalg.norm(self.detectors[0].position) * self.beam.direction\n",
    "        ax.plot([0, beam_cont[0]], [0, beam_cont[2]], [0, beam_cont[1]], 'k:')  # continued beam\n",
    "        # detectors\n",
    "        for detector in self.detectors:\n",
    "            pos = detector.position\n",
    "            ax.plot([0, pos[0]], [0, pos[2]], [0, pos[1]], 'k-')  # scattered beam\n",
    "        # components\n",
    "        for component, position in self.component_positions.items():\n",
    "            ax.plot(position[0], position[2], position[1], 'r+')\n",
    "            ax.text(position[0], position[2], position[1], s=component)\n",
    "\n",
    "        ax.set_xlabel('X [mm]')\n",
    "        ax.set_ylabel('Z [mm]')\n",
    "        ax.set_zlabel('Y [mm]')\n",
    "        ax.set_title(instrument_name)\n",
    "        # ax.set_aspect('equalxz')\n",
    "        fig.show()\n",
    "\n",
    "    def plot_wavevectors(self, figsize=[16, 6], dpi=100):\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "        pixel_centre = tuple([i // 2 for i in self.shape()])\n",
    "        ki = self.beam.incident_wavevector\n",
    "        detector_module = self.detectors[0].modules[0]\n",
    "        kf = detector_module.pixel_wavevector(pixel_centre, self.beam.wl)\n",
    "        q = kf - ki\n",
    "\n",
    "        ax.plot([-ki[0], 0], [-ki[2], 0], [-ki[1], 0], '-k')\n",
    "        ax.plot([0, kf[0]], [0, kf[2]], [0, kf[1]], '-k')\n",
    "        ax.plot([0, q[0]], [0, q[2]], [0, q[1]], '-r')\n",
    "\n",
    "        shape = self.shape()\n",
    "        wl = self.beam.wl\n",
    "        for frame in range(shape[0]):\n",
    "            corners = np.vstack([\n",
    "                detector_module.pixel_wavevector((frame, 0, 0), wl),  # module origin\n",
    "                detector_module.pixel_wavevector((frame, shape[1], 0), wl),  # module origin + slow pixels\n",
    "                detector_module.pixel_wavevector((frame, shape[1], shape[2]), wl),  # o + slow + fast\n",
    "                detector_module.pixel_wavevector((frame, 0, shape[2]), wl),  # o + fast\n",
    "                detector_module.pixel_wavevector((frame, 0, 0), wl),  # module origin\n",
    "            ])\n",
    "            ax.plot(corners[:, 0], corners[:, 2], corners[:, 1], '-k')\n",
    "            corners_q = corners - ki\n",
    "            ax.plot(corners_q[:, 0], corners_q[:, 2], corners_q[:, 1], '-r')\n",
    "\n",
    "        # plot Reciprocal lattice\n",
    "        astar, bstar, cstar = self.hkl2q(np.eye(3))\n",
    "        ax.plot([0, astar[0]], [0, astar[2]], [0, astar[1]], '-g')\n",
    "        ax.plot([0, bstar[0]], [0, bstar[2]], [0, bstar[1]], '-g')\n",
    "        ax.plot([0, cstar[0]], [0, cstar[2]], [0, cstar[1]], '-g')\n",
    "        ax.text(astar[0], astar[2], astar[1], s='a*')\n",
    "        ax.text(bstar[0], bstar[2], bstar[1], s='b*')\n",
    "        ax.text(cstar[0], cstar[2], cstar[1], s='c*')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.set_zlabel('Y')\n",
    "        ax.set_title(f\"HKL: {self.hkl(pixel_centre)}\")\n",
    "        ax.set_aspect('equal')\n",
    "        fig.show()\n",
    "\n",
    "    def plot_hkl(self, figsize=[16, 6], dpi=100):\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "        shape = self.shape()\n",
    "        pixel_centre = tuple([i // 2 for i in shape])\n",
    "        for frame in range(shape[0]):\n",
    "            corners = np.vstack([\n",
    "                self.hkl((frame, 0, 0)),  # module origin\n",
    "                self.hkl((frame, shape[1], 0)),  # module origin + slow pixels\n",
    "                self.hkl((frame, shape[1], shape[2])),  # o + slow + fast\n",
    "                self.hkl((frame, 0, shape[2])),  # o + fast\n",
    "                self.hkl((frame, 0, 0)),  # module origin\n",
    "            ])\n",
    "            ax.plot(corners[:, 0], corners[:, 2], corners[:, 1], '-r')\n",
    "        origin = self.hkl((0, 0, 0))\n",
    "        ax.plot(origin[0], origin[2], origin[1], '+k')\n",
    "\n",
    "        ax.set_xlabel('H')\n",
    "        ax.set_ylabel('L')\n",
    "        ax.set_zlabel('K')\n",
    "        ax.set_title(f\"HKL: {self.hkl(pixel_centre)}\")\n",
    "        ax.set_aspect('equal')\n",
    "        fig.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d30db05-517a-4c0f-afc7-26f07b6cb72c",
   "metadata": {},
   "source": [
    "# plot reciprocal space and instrument positions from NXtransformations\n",
    "with h5py.File(inpath) as nxs:\n",
    "    scan = NXScan(nxs)\n",
    "    scan.plot_wavevectors()\n",
    "\n",
    "    scan.plot_instrument()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbaba31b-2948-41ae-a17f-8cc3b6a6775e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {},
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
