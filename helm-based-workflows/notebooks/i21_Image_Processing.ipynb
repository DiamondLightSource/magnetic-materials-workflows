{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8490cc-6834-408b-ac0e-9261281e6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpath = 'mm1234-1/i21-157116.nxs'\n",
    "# outpath = 'mm1234-1/processed/i21-157116_output.nxs'\n",
    "# dark_image_file = 'mm1234-1/i21-157111.nxs'\n",
    "\n",
    "inpath = '/dls/i21/data/2025/cm40641-4/i21-437170.nxs'\n",
    "outpath = '/dls/i21/data/2025/cm40641-4/processed/i21-437170_processed.nxs'\n",
    "dark_image_file = '/dls/i21/data/2025/cm40641-4/i21-437149.nxs'\n",
    "energy_resolution = \"-0.006\"  # eV/px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d082e778-35ae-4e24-b74c-db6bd7b2c3a4",
   "metadata": {},
   "source": [
    "# I21 Image Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0379028-2407-49af-a804-8a773926ed88",
   "metadata": {},
   "source": [
    "Image processing notebook for I21 data analysis.\n",
    "\n",
    "The following steps will be made:\n",
    "1. Load scan image and dark image\n",
    "2. Process dark image and detemine scale factor\n",
    "3. Subtract dark image from scan image\n",
    "4. Find elastic line and fit slope\n",
    "5. Rotate image\n",
    "6. Fit position of elastic line in rotated image\n",
    "7. Rescale spectra for energy resolution\n",
    "\n",
    "**Run**\n",
    "\n",
    "To run this notebook automatically after a scan, add the scannable to the scan command:\n",
    "```\n",
    " scan ds 1 1 1 andor 20 processor\n",
    "```\n",
    "The results will automatically appear in [ispyb](ispyb.diamond.ac.uk) and outputs will appear in the *processed* folder.\n",
    "\n",
    "**Note**\n",
    "\n",
    "This notebook is a work in progress and still needs work to provide accurate results in all cases.\n",
    "\n",
    "To suggest improvements, please contact [dan.porter@diamond.ac.uk]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38969b9-dbaa-450e-8b4a-b7c20b75d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.ndimage import gaussian_filter, rotate\n",
    "from lmfit import Model\n",
    "from lmfit.models import GaussianModel, LinearModel\n",
    "from mmg_toolbox.fitting import multipeakfit\n",
    "from hdfmap import create_nexus_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dfa39-5908-464e-921a-5336645ec7d4",
   "metadata": {},
   "source": [
    "### 1. Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d6d63-d57c-4f59-9ec8-539b6a0bb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_map = create_nexus_map(dark_image_file)\n",
    "scan_map = create_nexus_map(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926da2f4-65f4-4fdd-a577-f34ee92085b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load detector arrays\n",
    "\n",
    "dark_map = create_nexus_map(dark_image_file)\n",
    "scan_map = create_nexus_map(inpath)\n",
    "\n",
    "with dark_map.load_hdf() as nxs:\n",
    "    detector = dark_map.get_image_path()\n",
    "    # dark_image = dark_map.get_data(nxs, detector)\n",
    "    dark_image = nxs[detector][...]\n",
    "    dark_count_time = dark_map.eval(nxs, 'count_time')\n",
    "    print(f\"Dark Detector: {detector}\")\n",
    "    print(f'Dark image: {dark_image.shape}')\n",
    "    print(f\"dark image intensity: max: {dark_image.max()}, min: {dark_image.min()}\")\n",
    "    print(f\"count_time: {dark_count_time}\")\n",
    "    dark_image = np.array([img / t for img, t in zip(dark_image, dark_count_time.reshape(-1))])\n",
    "\n",
    "with scan_map.load_hdf() as nxs:\n",
    "    detector = scan_map.get_image_path()\n",
    "    # scan_image = scan_map.get_data(nxs, detector)\n",
    "    scan_image = nxs[detector][...]\n",
    "    scan_count_time = scan_map.eval(nxs, 'count_time')\n",
    "    print(f\"\\nScan Detector: {detector}\")\n",
    "    print(f'Scan image: {scan_image.shape}')\n",
    "    print(f\"scan image intensity: max: {scan_image.max()}, min: {scan_image.min()}\")\n",
    "    print(f\"count_time: {scan_count_time}\")\n",
    "    scan_image = np.array([img / t for img, t in zip(scan_image, scan_count_time.reshape(-1))])\n",
    "\n",
    "# with h5py.File(dark_image_file, 'r') as nxs:\n",
    "#     dark_image_dataset = nxs['/entry1/xcam/data']\n",
    "#     count_time_dataset = nxs['/entry1/instrument/xcam/count_time']\n",
    "#     dark_image = dark_image_dataset[()]\n",
    "#     count_time = count_time_dataset[()]\n",
    "#     print(f'Dark image: {dark_image.shape}')\n",
    "#     print(f\"dark image intensity: max: {dark_image.max()}, min: {dark_image.min()}\")\n",
    "#     print(f\"count_time: {count_time}\")\n",
    "# with h5py.File(inpath, 'r') as nxs:\n",
    "#     scan_image_dataset = nxs['/entry1/xcam/data']\n",
    "#     count_time_dataset = nxs['/entry1/instrument/xcam/count_time']\n",
    "#     scan_image = scan_image_dataset[()]\n",
    "#     count_time = count_time_dataset[()]\n",
    "#     print(f'\\nScan image: {scan_image.shape}')\n",
    "#     print(f\"count_time: {count_time}\")\n",
    "\n",
    "# Image Intensity cut-offs\n",
    "cmin, cmax = np.min(scan_image[0]), np.min(scan_image[0]) + np.max(scan_image[0]) / 2\n",
    "print(f\"clim = {cmin}, {cmax}\")\n",
    "\n",
    "# Plot images\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[16, 4], dpi=80)\n",
    "\n",
    "ax1.imshow(dark_image[0], vmin=cmin+np.min(dark_image[0]), vmax=cmax+np.min(dark_image[0]))\n",
    "# ax1b = ax1.twiny()\n",
    "# ax1b.plot(dark_image[0].mean(axis=1), np.arange(dark_image.shape[1]), 'r-')\n",
    "# ax1b.margins(x=2)\n",
    "ax1.set_title('Dark Image');\n",
    "\n",
    "ax2.imshow(scan_image[0], vmin=cmin, vmax=cmax)\n",
    "# ax2b = ax2.twiny()\n",
    "# ax2b.plot(scan_image[0].mean(axis=1), np.arange(scan_image.shape[1]), 'r-')\n",
    "# ax2b.margins(x=2)\n",
    "ax2.set_title('Scan Image');\n",
    "\n",
    "ax3.plot(dark_image[0].mean(axis=1), label='Dark Image')\n",
    "ax3.plot(scan_image[0].mean(axis=1), label='Scan Image')\n",
    "ax3.legend()\n",
    "ax3.set_title('Average pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f4bbf-94cd-441a-98e4-3bb7620c1c67",
   "metadata": {},
   "source": [
    "### 2.1. Remove outliers from Dark image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65a55d-984d-4da5-a11a-519c685a4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove outliers\n",
    "\n",
    "# removeBlips2D \n",
    "# SubtractFittedBackgroundOperation \n",
    "# called by findDarkDataScaleAndOffset<getImage\n",
    "# https://github.com/DawnScience/scisoft-core/blob/0dbc6fda20bdd51b3059d901b4e0789173807663/uk.ac.diamond.scisoft.analysis.processing/src/uk/ac/diamond/scisoft/analysis/processing/operations/backgroundsubtraction/SubtractFittedBackgroundOperation.java#L801\n",
    "def remove_blips_2d(data, plot=False): \n",
    "    \"\"\"\n",
    "    Remove 'blips' (outlier pixels) from a 2D array using histogram fitting.\n",
    "    - data: 2D numpy array (will be modified in-place)\n",
    "    \"\"\"\n",
    "    # Step 1: crop detector sides\n",
    "    copy = 1 * data\n",
    "    data = copy[0, 10:-10, 10:-10]\n",
    "    \n",
    "    # Step 2: generate histogram of detector\n",
    "    nbins = min(int(data.max()), 1024 * 1024)\n",
    "    counts, bin_edges = np.histogram(data, bins=nbins)\n",
    "    bin_centres = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Step 2.5: select only the slice from one position to the let of the highest peak to the right half-max.\n",
    "    # This is done to get an accurate and reliable gaussian fit of the intensity distribution.\n",
    "    hist_max_idx = np.argmax(counts)\n",
    "    fit_counts = counts[hist_max_idx - 1 : len(counts) // 2]\n",
    "    fit_centres = bin_centres[hist_max_idx - 1 : len(counts) // 2]\n",
    "    \n",
    "    # Step 3: fit Gaussian to histogram\n",
    "    gmodel = GaussianModel()\n",
    "    params = gmodel.guess(counts, x=bin_centres)\n",
    "    c = np.argmax(counts)\n",
    "    params['center'].set(min=bin_centres[c - 1] - 0.5, max=bin_centres[c + 1])\n",
    "    # result = gmodel.fit(counts, params, x=bin_centres)\n",
    "    result = gmodel.fit(fit_counts, params, x=fit_centres)\n",
    "    # print(result.fit_report())\n",
    "    centre = result.best_values['center']\n",
    "    sigma = result.best_values['sigma']\n",
    "    fwhm = result.values['fwhm']\n",
    "    # fwhm = 2.3548200*sigma\n",
    "    print(f\"Centre: {centre}\\nFWHM: {fwhm}\") \n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(bin_centres, counts, label='Dark image histogram')\n",
    "        plt.plot(fit_centres, fit_counts, '--', label='Fit region')\n",
    "        plt.plot(bin_centres, result.eval(x=bin_centres), 'r-', label='Gaussian fit')\n",
    "        plt.xlim([0, 1000])\n",
    "        plt.xlabel('Dark image intensity')\n",
    "        plt.ylabel('Counts')\n",
    "        plt.legend()\n",
    "\n",
    "    # Step 4: Compute threshold\n",
    "    thr = centre + 2 * fwhm\n",
    "    print(f\"Blip threshold: {thr}\")\n",
    "\n",
    "    # Step 5: Iterate and replace blips\n",
    "    # We'll iterate row-wise, but you could also flatten the array and do similar\n",
    "    shape = data.shape\n",
    "    data_flat = data.ravel()\n",
    "    size = data_flat.size\n",
    "    i = 0\n",
    "    n_removed = 0\n",
    "    while i < size:\n",
    "        if abs(data_flat[i]) >= thr:\n",
    "            start = i\n",
    "            # Find the end of this blip region\n",
    "            while i < size and abs(data_flat[i]) >= thr:\n",
    "                i += 1\n",
    "            end = i\n",
    "            # Use average of previous and next pixel if possible\n",
    "            prev_val = data_flat[max(0, start-1)]\n",
    "            next_val = data_flat[min(i, size-1)]\n",
    "            fill_val = 0.5 * (prev_val + next_val)\n",
    "            max_val = np.max(data_flat[start:end])\n",
    "            data_flat[start:end] = fill_val\n",
    "            new_val = np.max(data_flat[start:end])\n",
    "            n_removed += 1\n",
    "            # print(f\"Blip removed at {start}:{end} = {np.unravel_index(start, shape)}, fill = {fill_val:.0f}, max = {max_val:.0f}, new = {new_val:.0f}\")\n",
    "        else:\n",
    "            i += 1\n",
    "    print(f\"Outliers removed: {n_removed}\")\n",
    "    copy[0, 10:-10, 10:-10] = data_flat.reshape(shape)\n",
    "    return copy\n",
    "\n",
    "print(f\"dark image intensity: max: {dark_image[0].max()}, min: {dark_image[0].min()}, argmax: {np.unravel_index(np.argmax(dark_image), dark_image.shape)}\")\n",
    "dark_image_rm_blips = remove_blips_2d(dark_image)\n",
    "print('\\nafter remove_blips_2d')\n",
    "print(f'Dark image: {dark_image_rm_blips.shape}')\n",
    "print(f\"dark image intensity: max: {dark_image_rm_blips.max()}, min: {dark_image_rm_blips.min()}, argmax: {np.unravel_index(np.argmax(dark_image_rm_blips), dark_image.shape)}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12, 4], dpi=80)\n",
    "ax1.imshow(dark_image[0], vmin=cmin+np.min(dark_image[0]), vmax=cmax+np.min(dark_image[0]))\n",
    "ax1.set_title('Dark Image')\n",
    "ax2.imshow(dark_image_rm_blips[0], vmin=cmin+np.min(dark_image[0]), vmax=cmax+np.min(dark_image[0]))\n",
    "ax2.set_title('Dark Image - After removing Cosmic rays')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeff2b7-7480-4dde-8506-aeee2e3126c0",
   "metadata": {},
   "source": [
    "### 2.2 Perform smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f7a1a-cf5a-4b9b-aa19-c3024e06be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Smooth the dark image\n",
    "# In java, this is a convolution of a 2D gaussian with the image. \n",
    "# Scipy's gaussian_filter is a sequence of 1D convolutions, \n",
    "# however the difference is minor.\n",
    "smoothing_sigma = 5  # Set according to needs\n",
    "smoothed_dark = gaussian_filter(dark_image_rm_blips, sigma=smoothing_sigma)\n",
    "print(f\"Smoothed dark image: {smoothed_dark.shape}\")\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[16, 4], dpi=80)\n",
    "ax1.imshow(dark_image[0], vmin=cmin+np.min(dark_image[0]), vmax=cmax+np.min(dark_image[0]))\n",
    "ax1.set_title('Dark Image')\n",
    "ax2.imshow(smoothed_dark[0], vmin=cmin+np.min(dark_image[0]), vmax=cmax+np.min(dark_image[0]))\n",
    "ax2.set_title('Smoothed Dark Image')\n",
    "ax3.plot(dark_image[0].sum(axis=1), label='Dark Image')\n",
    "ax3.plot(smoothed_dark[0].sum(axis=1), label='Smoothed Dark')\n",
    "ax3.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f0c1d-df51-4d11-9974-5317a6c03b5b",
   "metadata": {},
   "source": [
    "### 2.3 Determine scale and offset of dark image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363278c7-e1a2-436b-9656-fe961cc3279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.mean(smoothed_dark[0], axis=1)[50:-50]\n",
    "step = 10  # re-binning step size\n",
    "y2 = y[:len(y)- len(y) % step].reshape(-1, step).mean(axis=1)\n",
    "x2 = np.arange(len(y2)) * step\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(y, '-')\n",
    "ax.plot(x2, y2, '+')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(np.diff(y))\n",
    "ax2.plot(x2[:-1], np.diff(y2))\n",
    "# ax2.plot(np.gradient(y))\n",
    "ax2.set_ylim(-1, 1)\n",
    "\n",
    "fit_x = x2[:-1]\n",
    "fit_y = np.abs(np.diff(y2))\n",
    "params = {\n",
    "    'p1_center': fit_x[np.argmax(fit_y)],\n",
    "    'p1_fwhm': step,\n",
    "    'p1_height': fit_y.max(),\n",
    "}\n",
    "print(params)\n",
    "result = multipeakfit(fit_x, fit_y, initial_parameters=params, npeaks=1, plot_result=True, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5192a-cbd0-48c6-b2af-96034ac16f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Determine the scale and offset of the dark image at the drop-point\n",
    "def findDarkDataScaleAndOffset(image, smoothed_dark) -> tuple[float, float]:\n",
    "    y = np.mean(smoothed_dark[0], axis=1)[50:-50]  # crop start and end\n",
    "    drop_idx = np.argmin(np.diff(y))  # find drop-position from differential\n",
    "    \n",
    "    # rebin \n",
    "    step = 10  # re-binning step size\n",
    "    y2 = y[:len(y)- len(y) % step].reshape(-1, step).mean(axis=1)\n",
    "    drop_idx = np.argmin(np.diff(y2)) * step\n",
    "    \n",
    "    \n",
    "    # I've estimated the the FWHM of the drop here, \n",
    "    # in Java it is done by finding the distance between cross-points \n",
    "    # where the differential is half the minimum.\n",
    "    drop_fwhm = 100 \n",
    "    # The width of the fit slice is a factor (given by the model, 5 default and doubled) \n",
    "    # of the FWHM of negative peak in the derivative of smoothed and 1-D mean background profile\n",
    "    user_width_param = 5\n",
    "    drop_fwhm = user_width_param * drop_fwhm\n",
    "    fitSlice = (drop_idx-drop_fwhm, drop_idx+drop_fwhm)  \n",
    "    clippedBackground = smoothed_dark[0, fitSlice[0]+50:fitSlice[1]+50, :]\n",
    "    clippedImage = image[0, fitSlice[0]+50:fitSlice[1]+50, :]  # == \"in\"\n",
    "    offset = clippedImage.mean() - clippedBackground.mean()\n",
    "    print('Guessed Offset = ', offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.mean(dark_image[0], axis=1)[50:-50], label='dark image profile')\n",
    "    plt.plot(np.mean(smoothed_dark[0], axis=1)[50:-50], label='smoothed dark profile')\n",
    "    plt.axvline(drop_idx, c='k', label='drop')\n",
    "    plt.title('dark image drop')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.gca().twinx()\n",
    "    plt.plot(np.diff(y), c='c', label='diff')\n",
    "    plt.ylim([-5, 5])\n",
    "    plt.ylabel('diff', c='c')\n",
    "\n",
    "    # Fit a line to the background vs image intensity\n",
    "    # the image used here is cropped, with outliers removed\n",
    "    xvals = clippedBackground.ravel()\n",
    "    yvals = remove_blips_2d(image)[0, fitSlice[0]+50:fitSlice[1]+50, :].ravel()\n",
    "    \n",
    "    model = LinearModel()\n",
    "    result = model.fit(yvals, x=xvals, slope=1, intercept=offset)\n",
    "    scale = result.params['slope'].value\n",
    "    offset = result.params['intercept'].value\n",
    "    # print(result.fit_report())\n",
    "    print(f\"scale: {scale:.3g}, offset: {offset:.3g}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xvals, yvals, '.', label='Intensities')\n",
    "    plt.plot(np.array([np.min(xvals), np.max(xvals)]), result.eval(x=np.array([np.min(xvals), np.max(xvals)])), '-r', label='fit')\n",
    "    plt.xlabel('Background intensity')\n",
    "    plt.ylabel('Image intensity')\n",
    "    plt.title('Background scaling fit')\n",
    "    plt.legend()\n",
    "    return scale, offset\n",
    "\n",
    "scaleOffset = findDarkDataScaleAndOffset(scan_image, smoothed_dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c16fbe-2edd-4a9d-8ef0-773814c81b7f",
   "metadata": {},
   "source": [
    "### 3. Subtract scaled dark image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba7768-73e8-4d1f-afea-4a41acb5513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Subtract scaled dark image from scan image\n",
    "scale, offset = scaleOffset\n",
    "subtractCrop = (smoothed_dark * scale) + offset\n",
    "darkFit = np.mean(subtractCrop[0], axis=1)[50:-50]\n",
    "profile = np.mean(scan_image[0], axis=1)[50:-50]\n",
    "\n",
    "\n",
    "subtracted = scan_image[0] - subtractCrop[0]\n",
    "sub_profile = np.mean(subtracted, axis=1)[50:-50]\n",
    "scmin, scmax = 0, np.max(subtracted) / 10\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=[12, 8], dpi=100)\n",
    "axes[0, 0].imshow(scan_image[0], vmin=cmin, vmax=cmax)\n",
    "axes[0, 0].set_title('Scan Image')\n",
    "axes[0, 1].imshow(subtracted, vmin=scmin, vmax=scmax)\n",
    "axes[0, 1].set_title('Scan Image - Scaled Dark Image')\n",
    "\n",
    "axes[1, 0].plot(profile, label='scan image')\n",
    "axes[1, 0].plot(darkFit, label='dark image')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 1].plot(sub_profile, label='scan image - scaled dark image')\n",
    "axes[1, 1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cc24e-1744-4cf1-be4e-7809d39d4d44",
   "metadata": {},
   "source": [
    "### 4.1 Find elastic peak region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba69fa-beaf-42ed-9ce1-def0975afe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Find Region of Interest\n",
    "\n",
    "# 4.1 remove edges\n",
    "roi = subtracted[10:-10, 10:-10]\n",
    "\n",
    "# 4.2 fit integrated intensity along x-axis to determine x-region\n",
    "result_x = multipeakfit(np.arange(roi.shape[1]), roi.mean(axis=0), npeaks=1, print_result=False, plot_result=True)\n",
    "x_peak = result_x.p1_center\n",
    "x_roimin, x_roimax = int(result_x.p1_center - result_x.p1_fwhm), int(result_x.p1_center + result_x.p1_fwhm)\n",
    "\n",
    "roi = roi[:, x_roimin:x_roimax]\n",
    "xval, yval = np.arange(roi.shape[0]), roi.mean(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(roi, vmin=scmin, vmax=scmax)\n",
    "plt.plot(yval, xval, 'w-')\n",
    "ax = plt.gca()\n",
    "\n",
    "# 4.3 fit integrated intensity along y-axis to determine y-region\n",
    "result_y = multipeakfit(xval, yval, print_result=False, plot_result=True)\n",
    "if not hasattr(result_y, 'p1_center'):\n",
    "    raise Exception('No Peaks found in y-region')\n",
    "\n",
    "y_roimin, y_roimax = int(result_y.p1_center - result_y.p1_fwhm), int(result_y.p1_center + result_y.p1_fwhm)\n",
    "ax.axhline(result_y.p1_center, c='r')\n",
    "\n",
    "roi = roi[y_roimin:y_roimax, :]\n",
    "xval, yval = np.arange(roi.shape[0]), roi.mean(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(roi, vmin=scmin, vmax=scmax)\n",
    "plt.plot(yval, xval, 'w-')\n",
    "\n",
    "# offset values to recover original image index\n",
    "x_roi_offset = 10 + x_roimin\n",
    "y_roi_offset = 10 + y_roimin\n",
    "print(f\"ROI offsets: {x_roi_offset}, {y_roi_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69f96b-84ef-4b58-92a0-54f6ff792dfe",
   "metadata": {},
   "source": [
    "### 4.2 Fit straight line against max pixels in region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051038f-57e8-4bce-bc3c-b0e2cc60bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. determine line position along x-axis using averaged location of max pixel\n",
    "step = 100\n",
    "argmaxes = np.array([\n",
    "    [\n",
    "        x + step/2, \n",
    "        np.argmax(line := roi[:, x:x+step].sum(axis=1)), \n",
    "        line.max()\n",
    "    ] for x in range(0, roi.shape[1], step)\n",
    "    if x + step <= roi.shape[1]\n",
    "])\n",
    "\n",
    "# Fit straight line against max pixel locations\n",
    "model = LinearModel()\n",
    "pars = model.guess(argmaxes[:, 1], argmaxes[:, 0])\n",
    "linefit = model.fit(argmaxes[:, 1], x=argmaxes[:, 0], params=pars, weights=argmaxes[:, 2])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(roi, vmin=scmin, vmax=scmax)\n",
    "plt.plot(argmaxes[:, 0], argmaxes[:, 1], 'y+')\n",
    "plt.plot(argmaxes[:, 0], linefit.best_fit, 'w-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01f210-d2be-4ce0-862f-42ae978309d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fitted line position\n",
    "x_pos = int(result_x.p1_center) + 10\n",
    "y_pos = linefit.eval(x=x_pos - x_roi_offset) + y_roi_offset\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=[12, 8], dpi=100)\n",
    "fig.suptitle('Check Elastic Line Fit')\n",
    "axes[0, 0].imshow(subtracted, vmin=scmin, vmax=scmax)\n",
    "axes[0, 0].plot(argmaxes[:, 0] + x_roi_offset, linefit.best_fit + y_roi_offset, 'w-', lw=0.5)\n",
    "axes[0, 1].imshow(subtracted, vmin=scmin, vmax=scmax)\n",
    "axes[0, 1].plot(argmaxes[:, 0] + x_roi_offset, linefit.best_fit + y_roi_offset, 'w-', lw=0.5)\n",
    "axes[0, 1].set_xlim(x_pos - 500, x_pos + 100)\n",
    "axes[0, 1].set_ylim(y_pos + 100, y_pos - 100)\n",
    "\n",
    "axes[1, 0].plot(subtracted[:, x_pos - step//2: x_pos + step//2].mean(axis=1))\n",
    "axes[1, 0].axvline(y_pos, c='r', label='bin')\n",
    "# axes[1, 1].plot(subtracted[:, x_pos - step: x_pos].mean(axis=1))\n",
    "axes[1, 1].plot(subtracted[:, x_pos - step//2: x_pos + step//2].mean(axis=1))\n",
    "# axes[1, 1].plot(subtracted[:, x_pos: x_pos + step].mean(axis=1))\n",
    "axes[1, 1].axvline(y_pos, c='r', label='bin')\n",
    "axes[1, 1].set_xlim(y_pos - 100, y_pos + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd1f37-f7c8-416d-b164-2e5390cad01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Results\n",
    "slope = linefit.params['slope'].value\n",
    "intercept = linefit.params['intercept'].value + y_roi_offset\n",
    "\n",
    "print(\"Line Fit Results:\")\n",
    "print(f\"Slope: {slope:.3g} +/- {linefit.params['slope'].stderr:.2g}\")\n",
    "print(f\"Interccept: {intercept:.3g} +/- {linefit.params['intercept'].stderr:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbacae1-2f0e-465e-9f72-e45fd1c11ee2",
   "metadata": {},
   "source": [
    "### 5. Rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a19ed-38c4-43de-bf1a-13061e354a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Rotate detectro image by slope\n",
    "angle = np.arctan(linefit.params['slope'].value)\n",
    "print(f\"Slope angle = {angle:.3g} rad = {np.rad2deg(angle):.3g} deg\")\n",
    "rotated = rotate(subtracted, angle=np.rad2deg(angle))  # uses interpolation\n",
    "rotated_intercept = intercept * np.cos(angle)\n",
    "\n",
    "# rotation is about image centre, subtract initial centre\n",
    "x, y = (\n",
    "    x_peak - subtracted.shape[1]/2, \n",
    "    intercept - subtracted.shape[0]/2\n",
    ")\n",
    "# rotate pixels\n",
    "rx, ry = (x * np.cos(angle) + y * np.sin(angle), -x * np.sin(angle) + y * np.cos(angle))\n",
    "# add rotated image centre\n",
    "rotated_intercept = ry + rotated.shape[0]/2\n",
    "print('Rotated intercept:', rotated_intercept)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=[12, 8], dpi=100)\n",
    "fig.suptitle('Check Image Rotation')\n",
    "axes[0, 0].imshow(subtracted, vmin=scmin, vmax=scmax)\n",
    "axes[0, 0].axhline(intercept, c='r', lw=0.5)\n",
    "axes[0, 1].imshow(rotated, vmin=scmin, vmax=scmax)\n",
    "axes[0, 1].axhline(rotated_intercept, c='r', lw=0.5)\n",
    "\n",
    "axes[1, 0].plot(subtracted[:, x_pos - step//2: x_pos + step//2].mean(axis=1), label='Image - bkg')\n",
    "axes[1, 0].plot(rotated[:, x_pos - step//2: x_pos + step//2].mean(axis=1), label='Rotated image')\n",
    "axes[1, 0].axvline(intercept, c='r', label='Elastic line')\n",
    "axes[1, 0].axvline(rotated_intercept, c='r', label='Elastic line (rotated)')\n",
    "\n",
    "axes[1, 1].plot(subtracted[:, x_pos - step//2: x_pos + step//2].mean(axis=1), label='Image - bkg')\n",
    "axes[1, 1].plot(rotated[:, x_pos - step//2: x_pos + step//2].mean(axis=1), label='Rotated image')\n",
    "axes[1, 1].axvline(intercept, c='r', label='Elastic line')\n",
    "axes[1, 1].axvline(rotated_intercept, c='r', label='Elastic line (rotated)')\n",
    "axes[1, 1].set_xlim(y_pos - 100, y_pos + 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f0c25-7211-41c3-b03e-bae9eb26e6e7",
   "metadata": {},
   "source": [
    "### 6. Find Elastic line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6597b5-421d-48fa-b324-41aa6481fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intercept, rotated_intercept)\n",
    "print(y_roimin - intercept + rotated_intercept, y_roimax - intercept + rotated_intercept, x_roimin, x_roimax)\n",
    "rotated_roi = rotated[int(y_roimin - intercept + rotated_intercept):int(y_roimax - intercept + rotated_intercept), x_roimin:x_roimax]\n",
    "yval = np.mean(rotated_roi, axis=1)\n",
    "xval = np.arange(len(yval))\n",
    "\n",
    "plt.imshow(rotated_roi, vmin=scmin, vmax=scmax)\n",
    "\n",
    "result_r = multipeakfit(xval, yval, print_result=False, plot_result=True)\n",
    "if not hasattr(result_r, 'p1_center'):\n",
    "    raise Exception('No Peaks found in y-region')\n",
    "elastic_intercept = result_r.p1_center + y_roimin - intercept + rotated_intercept\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=[12, 4], dpi=100)\n",
    "fig.suptitle('Check Fit Elastic line')\n",
    "axes[0].imshow(rotated, vmin=scmin, vmax=scmax)\n",
    "axes[0].axhline(elastic_intercept, c='r', lw=0.5)\n",
    "axes[1].plot(rotated.mean(axis=1), label='Rotated image')\n",
    "axes[1].axvline(elastic_intercept, c='r', label='Elastic line')\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21462716-2eba-413e-9c7e-80ccf591ef7a",
   "metadata": {},
   "source": [
    "### 7. Scale by energy resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0375f2-ac6f-4bed-a526-a51a3af0499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Scale and sum spectra\n",
    "energy = (np.arange(rotated.shape[0]) - elastic_intercept ) * float(energy_resolution)\n",
    "spectra = rotated.sum(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(energy, spectra)\n",
    "plt.xlabel('energy [eV]')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title(os.path.basename(inpath))\n",
    "plt.savefig('/tmp/result.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f11ce-8388-41db-bff3-ff87966e130e",
   "metadata": {},
   "source": [
    "### 8. Write output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0e330-be49-4162-b072-d5b0b22da9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write nexus file\n",
    "# Not done yet!\n",
    "\n",
    "# Write ascii file\n",
    "header = f\"{inpath}\\nProcessed by 'i21_Image_Processing.ipynb'\\n energy [eV], intensity\"\n",
    "np.savetxt('/tmp/result.dat', (energy, spectra), header=header)\n",
    "np.savetxt(outpath[:-4] + '.dat', (energy, spectra), header=header)\n",
    "if os.path.isfile(outpath[:-4] + '.dat'):\n",
    "    print(f'Saved file: {outpath[:-4] + '.dat'}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ec704-9d03-4cdb-ab03-3c02fb2fdd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
